?sum
?dnorm
dnorm(10, mean=0, sd=1, log=FALSE)
pnoem(1.96)
pnorm(1.96)
qnorm(.975)
rnorm(10)
x <- rnorm(10)
dnorm(x)
dnorm(.5)
dnorm(0)
dnorm(1)
dnorm(-1)
4*12*(0:2)
install.packages("fpp")
library(fpp)
data(tute1)
tute1 <- read.csv("C:/Users/Subroto/Coursera/PracticalMachineLearning_May_2015/downloads/tute1.csv")
View(tute1)
names(tute1)
class(tute1$X)
tutex <- ts(tute1[,-1], start=1981, frequency=4)
class(tutex)
names(tutex)
summary(tutex)
print(tutex)
?ts
names(tutex)
tutex
tutex$ts
plot(tutex)
tutex[1,]
tutex[,1]
dim(tutex)
head(tutex[,1])
names(tutex[,1])
names(tutex[,2])
head(tutex[,2])
sumarry(tutex)
summary(tutex)
?plot.ts
tutey <- ts(tute1[,-1], start=1982, frequency=4)
tutey
seasonplot(tutex[,"Sales"])
seasonplot(tutex[,"AdBudget"])
seasonplot(tutex[,"GDP"])
monthplot(tutex[,"GDP"])
monthplot(tutex[,"Sales"])
monthplot(tutex[,"AdBudget"])
plot(Sales ~ AdBudget, data=tutex)
abline(lm(Sales ~ AdBudget, data=tutex))
plot(Sales ~ GDP, data=tutex)
abline(lm(Sales ~ GDP, data=tutex))
cor.test(tutex[,"Sales"],tutex[,"AdBudget"])
cor.test(tutex[,"Sales"],tutex[,"GDP"])
pairs(as.data.frame(tutex))
install.packages("shiny")
library(shiny)
library(Rtools)
install.packages("Rtools")
library(Rtools)
library(devtools)
install.packages("devtools")
library(devtools)
install.packages("Rtools")
find.package("devtools")
library(devtools)
find_rtools()
data(cars)
names(cars)
cars
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
?abline
library(rCharts)
install.packages("rCharts")
find_rtools()
?dtable
library(rCharts)
require(devtools)
install_github('rCharts', 'ramnathv')
?rTable
?dTable
??dTable
dTable
library(rCharts)
?dTable
??dTable
data(economics, package = "ggplot2")
econ <- transform(economics, date = as.character(date))
m1 <- mPlot(x = "date", y = c("psavert", "uempmed"), type = "Line", data = econ)
m1$set(pointSize = 0, lineWidth = 1)
m1$print("chart2")
data(iris)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
find("shiny")
find("rTools")
?find
ls()
?lib
?libraries
library
library()
search()
data(HairEyeColor)
names(HairEyeColor)
library(lattice)
data(HairEyeColor)
names(HairEyeColor)
install.package("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
library(datasets)
datasets
search(HairEyeColor)
find(HairEyeColor)
search()
data(HairEyeColor)
names(HairEyeColor)
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
library(rCharts)
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
data(airquality)
dTable(airquality, sPaginationType = "full_numbers")
search()
library(shiny)runExample("01_hello")
library(shiny)runExample("01_hello")
runExample("01_hello")
library)shiny)
library(shiny)
runExample("01_hello")
library(caret)
args(train)
args(train.default)
args(trainControl)
rbinom(10, size=1, prob=.5)
rbinom(10, size=1, prob=.5)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
rbinom(10, size=1, prob=.1)
a <- 1:100
class()
class(a)
quantile(a)
a[1:30] <- repeat(1,30)
?repeat
?sel
??rep
?rep
a[1:30] <- rep(1,30)
quantile(a)
a[70:100] <- rep(4,30)
a[70:100] <- rep(4)
tail(a)
quantile(a)
?order
?factor
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
names(training) %contains% "^IL"
"^IL" %in% names(training)
?grep
grap("^IL", names(training))
grep("^IL", names(training))
grep("^IL", names(training), value=TRUE)
x <- paste(grep("^IL", names(training), value=TRUE), sep="+")
x
?paste
x <- grep("^IL", names(training), value=TRUE))
x <- grep("^IL", names(training), value=TRUE)
x
class(x)
y <- paste(x, sep="+")
y
toString(x)
y <- paste(toString(x), sep="+")
y
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep("^IL", names(training), value=TRUE)
?preProcess
valset <- training[, names(training) %in% grep("^IL", names(training), value=TRUE)]
names(valset)
class(valset)
preproc <- preProcess(valset, method="pca", thresh=0.8)
summary(preProc)
summary(preproc)
print(preproc)
trainSet <- predict(preproc, training)
trainSet <- predict(preproc, training[,names(training) %in% grep("^IL", names(training), value=TRUE)])
names(training)
modelFit <- train(training$diagnosis ~ ., method="glm", data=trainSet)
modelFit$finalModel
confusionMatrix(predict(modelFit, data=trainSet), training$diagnosis)
confusionMatrix(training$diagnosis, predict(modelFit, data=trainSet))
names(trainSet)
length(training$diagnosis)
dim(trainSet)
modelY <- train(training$diagnosis ~ ., method="glm", data=testing)
modelY <- train(training$diagnosis ~ ., method="glm", data=testing[,names(testing) %in% grep("^IL", names(testing), value=TRUE)])
modelY <- train(testing$diagnosis ~ ., method="glm", data=testing[,names(testing) %in% grep("^IL", names(testing), value=TRUE)])
modelY <- train(training$diagnosis ~ ., method="glm", data=training[,names(training) %in% grep("^IL", names(training), value=TRUE)])
confusionMatrix(predict(modelY, data=testing), testing$diagnosis)
modelY <- train(training$diagnosis ~ ., method="glm", data=training[,names(training) %in% grep("^IL", names(training), value=TRUE)])
modelY$finalModel
predict(modelY, data=training[,names(training) %in% grep("^IL", names(training), value=TRUE)])
predict(modelY, data=valset)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## create a dataset only containing variables starting with IL using training data
valset <- training[, names(training) %in% grep("^IL", names(training), value=TRUE)]
modelFitNoPCA <- train(training$diagnosis ~ ., method="glm", data=valset)
modelFitNoPCA$fitted
print(modelFitNoPCA)
predict(modelFitNoPCA, valset)
consudionMatrix(training$diagnosis, predict(modelFitNoPCA, valset))
confusionMatrix(training$diagnosis, predict(modelFitNoPCA, valset))
modelFitNoPCA <- train(training$diagnosis ~ ., method="glm", data=testset)
testset <- testing[, names(testing) %in% grep("^IL", names(testing), value=TRUE)]
predict(modelFitNoPCA, testset)
confusionMatrix(testing$diagnosis, predict(modelFitNoPCA, testset))
confusionMatrix(testing$diagnosis, predict(modelFitNoPCA, testset))
trainset <- training[, names(training) %in% grep("^IL", names(training), value=TRUE)]
testset <- testing[, names(testing) %in% grep("^IL", names(testing), value=TRUE)]
preproc <- preProcess(valset, method="pca", thresh=0.8)
trainsetPCA <- predict(preproc, trainset)
testsetPCA <- predict(preproc, testset)
modelFitPCA <- train(training$diagnosis ~ ., method="glm", data=trainsetPCA)
confusionMatrix(testing$diagnosis, predict(modelFitNoPCA, testsetPCA))
confusionMatrix(testing$diagnosis, predict(modelFitPCA, testsetPCA))
?colors
?plot
?unlist
?levels
?level
?relevel
data(anscombe)
head(anscombe)
a <- with(anscombe)
anscombeA <- with(anscombe, {
y1[1:3] <- NA
})
anscombeA
anscombeA <- within(anscombe, {
y1[1:3] <- NA
})
anscombeA
?within
?colSums
?str
?aggregate
?transform
?seq_len
?tapply
a <- list(x=c(1,2), y=c("a", "b") )
names(a)
class(a)
a[1]
a[2]
length(a)
length(a[1])
a[1]
a[1][1]
a$1
a$1[1]
a
a$a
a$x
a$x[2]
gwtwd()
getwd()
setwd("C:/Users/Subroto/Coursera/ReproducibleResearch_July_2015/Projects/RepData_PeerAssessment1")
getwd()
setwd
setwd()
install.packages("xtable")
library(xtable)
